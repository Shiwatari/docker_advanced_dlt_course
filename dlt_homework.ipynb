{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#extract\n",
    "os.environ['EXTRACT__WORKERS'] = '3'\n",
    "#os.environ[\"EXTRACT__DATA_WRITER__FILE_MAX_ITEMS\"] = \"100000\"\n",
    "#normalize\n",
    "os.environ['NORMALIZE__WORKERS'] = '5'\n",
    "os.environ['NORMALIZE__DATA_WRITER__BUFFER_MAX_ITEMS'] = '5000'\n",
    "os.environ[\"NORMALIZE__DATA_WRITER__FILE_MAX_ITEMS\"] = \"5000\"\n",
    "#load\n",
    "os.environ['LOAD__WORKERS'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cb87422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "from dlt.sources.helpers.rest_client import RESTClient\n",
    "from dlt.sources.helpers.rest_client.paginators import HeaderLinkPaginator\n",
    "from itertools import islice\n",
    "from retrying import retry\n",
    "\n",
    "def yield_chunks(iterable, chunk_size=10):\n",
    "    iterator = iter(iterable)\n",
    "    while chunk := islice(iterator, chunk_size):  # <--- we slice data into chunks\n",
    "        yield chunk\n",
    "\n",
    "\n",
    "@dlt.source\n",
    "def jaffle_source():\n",
    "    client = RESTClient(\n",
    "            base_url=\"https://jaffle-shop.scalevector.ai/api/v1\",\n",
    "            paginator=HeaderLinkPaginator(),\n",
    "    )\n",
    "\n",
    "    @dlt.resource(table_name=\"jaffle_customers\", write_disposition=\"merge\", primary_key=\"id\", parallelized=True)\n",
    "    def jaffle_customers():\n",
    "      for page in client.paginate(\"customers\"):\n",
    "        yield page\n",
    "\n",
    "    #@retry(wait_random_min=1000, wait_random_max=2000, stop_max_attempt_number=10)\n",
    "    @dlt.resource(table_name=\"jaffle_orders\", write_disposition=\"merge\", primary_key=\"id\", parallelized=True)\n",
    "    def jaffle_orders():\n",
    "      params = {\n",
    "            \"page_size\": 5000 #with the limit set to 100 the pipeline ran for approximately 10 minutes\n",
    "        }\n",
    "      for attempt in range(10):\n",
    "        try:\n",
    "          for page in client.paginate(\"orders\", params=params):\n",
    "            yield page\n",
    "        except Exception as e:\n",
    "          pass\n",
    "        else:\n",
    "          break\n",
    "         \n",
    "      #yield from yield_chunks(client.paginate(\"orders\", params=params), chunk_size=10) #yielding chunks seems to overburden the api, causing excessively long load time, execution was stopped after 37 minutes\n",
    "\n",
    "    @dlt.resource(table_name=\"jaffle_products\", write_disposition=\"merge\", primary_key=\"sku\", parallelized=True)\n",
    "    def jaffle_products():\n",
    "      for page in client.paginate(\"products\"):\n",
    "        yield page\n",
    "\n",
    "    return jaffle_customers,jaffle_orders,jaffle_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c3d5d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run started at 2025-05-21 15:41:52.265628+00:00 and COMPLETED in 24 minutes and 30.13 seconds with 4 steps.\n",
      "Step extract COMPLETED in 23 minutes and 39.07 seconds.\n",
      "\n",
      "Load package 1747842112.3093712 is EXTRACTED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step normalize COMPLETED in 29.00 seconds.\n",
      "Normalized data for the following tables:\n",
      "- _dlt_pipeline_state: 1 row(s)\n",
      "- jaffle_customers: 935 row(s)\n",
      "- jaffle_products: 10 row(s)\n",
      "- jaffle_orders: 86948 row(s)\n",
      "- jaffle_orders__items: 128577 row(s)\n",
      "\n",
      "Load package 1747842112.3093712 is NORMALIZED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step load COMPLETED in 22.03 seconds.\n",
      "Pipeline jaffle_shop_pipeline load step completed in 21.98 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset jaffle_stage_20250521034152\n",
      "The duckdb destination used duckdb:////workspaces/docker_advanced_dlt_course/jaffle_shop_pipeline.duckdb location to store data\n",
      "Load package 1747842112.3093712 is LOADED and contains no failed jobs\n",
      "\n",
      "Step run COMPLETED in 24 minutes and 30.12 seconds.\n",
      "Pipeline jaffle_shop_pipeline load step completed in 21.98 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset jaffle_stage_20250521034152\n",
      "The duckdb destination used duckdb:////workspaces/docker_advanced_dlt_course/jaffle_shop_pipeline.duckdb location to store data\n",
      "Load package 1747842112.3093712 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"jaffle_shop_pipeline\",\n",
    "    destination=\"duckdb\",\n",
    "    dataset_name=\"jaffle_stage\",\n",
    "    dev_mode=True,\n",
    ")\n",
    "\n",
    "load_info = pipeline.run(jaffle_source())\n",
    "print(pipeline.last_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dcb0f2",
   "metadata": {},
   "source": [
    "####Performance testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468de794",
   "metadata": {},
   "source": [
    "first perf trial with the following settings:\n",
    "os.environ['EXTRACT__WORKERS'] = '3'\n",
    "os.environ['NORMALIZE__WORKERS'] = '2'\n",
    "os.environ['LOAD__WORKERS'] = '2'\n",
    "\n",
    "runtime: 6min 46sec\n",
    "\n",
    "output:\n",
    "Run started at 2025-05-21 10:09:02.540887+00:00 and COMPLETED in 6 minutes and 45.37 seconds with 4 steps.\n",
    "Step extract COMPLETED in 5 minutes and 53.30 seconds.\n",
    "\n",
    "Load package 1747822142.5831456 is EXTRACTED and NOT YET LOADED to the destination and contains no failed jobs\n",
    "\n",
    "Step normalize COMPLETED in 27.44 seconds.\n",
    "Normalized data for the following tables:\n",
    "- _dlt_pipeline_state: 1 row(s)\n",
    "- jaffle_customers: 935 row(s)\n",
    "- jaffle_orders: 61948 row(s)\n",
    "- jaffle_orders__items: 90900 row(s)\n",
    "- jaffle_products: 10 row(s)\n",
    "\n",
    "Load package 1747822142.5831456 is NORMALIZED and NOT YET LOADED to the destination and contains no failed jobs\n",
    "\n",
    "Step load COMPLETED in 24.51 seconds.\n",
    "Pipeline jaffle_shop_pipeline load step completed in 24.46 seconds\n",
    "1 load package(s) were loaded to destination duckdb and into dataset jaffle_stage_20250521100902\n",
    "The duckdb destination used duckdb:////workspaces/docker_advanced_dlt_course/jaffle_shop_pipeline.duckdb location to store data\n",
    "Load package 1747822142.5831456 is LOADED and contains no failed jobs\n",
    "\n",
    "Step run COMPLETED in 6 minutes and 45.37 seconds.\n",
    "Pipeline jaffle_shop_pipeline load step completed in 24.46 seconds\n",
    "1 load package(s) were loaded to destination duckdb and into dataset jaffle_stage_20250521100902\n",
    "The duckdb destination used duckdb:////workspaces/docker_advanced_dlt_course/jaffle_shop_pipeline.duckdb location to store data\n",
    "Load package 1747822142.5831456 is LOADED and contains no failed jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118dba7",
   "metadata": {},
   "source": [
    "####V3 keeping the parameters, but setting the size of the pages to 100 causes the extract step to be significantly slower.\n",
    "Run started at 2025-05-21 12:41:11.649454+00:00 and COMPLETED in 6 minutes and 53.75 seconds with 4 steps.\n",
    "Step extract COMPLETED in 6 minutes and 12.53 seconds.\n",
    "\n",
    "Load package 1747831271.7042348 is EXTRACTED and NOT YET LOADED to the destination and contains no failed jobs\n",
    "\n",
    "Step normalize COMPLETED in 22.03 seconds.\n",
    "Normalized data for the following tables:\n",
    "- _dlt_pipeline_state: 1 row(s)\n",
    "- jaffle_customers: 935 row(s)\n",
    "- jaffle_orders: 61948 row(s)\n",
    "- jaffle_orders__items: 90900 row(s)\n",
    "- jaffle_products: 10 row(s)\n",
    "\n",
    "Load package 1747831271.7042348 is NORMALIZED and NOT YET LOADED to the destination and contains no failed jobs\n",
    "\n",
    "Step load COMPLETED in 19.14 seconds.\n",
    "Pipeline jaffle_shop_pipeline load step completed in 19.08 seconds\n",
    "1 load package(s) were loaded to destination duckdb and into dataset jaffle_stage_20250521124111\n",
    "The duckdb destination used duckdb:////workspaces/docker_advanced_dlt_course/jaffle_shop_pipeline.duckdb location to store data\n",
    "Load package 1747831271.7042348 is LOADED and contains no failed jobs\n",
    "\n",
    "Step run COMPLETED in 6 minutes and 53.74 seconds.\n",
    "Pipeline jaffle_shop_pipeline load step completed in 19.08 seconds\n",
    "1 load package(s) were loaded to destination duckdb and into dataset jaffle_stage_20250521124111\n",
    "The duckdb destination used duckdb:////workspaces/docker_advanced_dlt_course/jaffle_shop_pipeline.duckdb location to store data\n",
    "Load package 1747831271.7042348 is LOADED and contains no failed jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24feb18b",
   "metadata": {},
   "source": [
    "####V2\n",
    "updating the buffer size and file rotation parameters yielded a small performance improvement\n",
    "output:\n",
    "\n",
    "Run started at 2025-05-21 10:32:08.689815+00:00 and COMPLETED in 6 minutes and 25.53 seconds with 4 steps.\n",
    "Step extract COMPLETED in 5 minutes and 41.39 seconds.\n",
    "\n",
    "Load package 1747823528.7447271 is EXTRACTED and NOT YET LOADED to the destination and contains no failed jobs\n",
    "\n",
    "Step normalize COMPLETED in 23.37 seconds.\n",
    "Normalized data for the following tables:\n",
    "- _dlt_pipeline_state: 1 row(s)\n",
    "- jaffle_customers: 935 row(s)\n",
    "- jaffle_orders: 61948 row(s)\n",
    "- jaffle_orders__items: 90900 row(s)\n",
    "- jaffle_products: 10 row(s)\n",
    "\n",
    "Load package 1747823528.7447271 is NORMALIZED and NOT YET LOADED to the destination and contains no failed jobs\n",
    "\n",
    "Step load COMPLETED in 20.74 seconds.\n",
    "Pipeline jaffle_shop_pipeline load step completed in 20.69 seconds\n",
    "1 load package(s) were loaded to destination duckdb and into dataset jaffle_stage_20250521103208\n",
    "The duckdb destination used duckdb:////workspaces/docker_advanced_dlt_course/jaffle_shop_pipeline.duckdb location to store data\n",
    "Load package 1747823528.7447271 is LOADED and contains no failed jobs\n",
    "\n",
    "Step run COMPLETED in 6 minutes and 25.53 seconds.\n",
    "Pipeline jaffle_shop_pipeline load step completed in 20.69 seconds\n",
    "1 load package(s) were loaded to destination duckdb and into dataset jaffle_stage_20250521103208\n",
    "The duckdb destination used duckdb:////workspaces/docker_advanced_dlt_course/jaffle_shop_pipeline.duckdb location to store data\n",
    "Load package 1747823528.7447271 is LOADED and contains no failed jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c02032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
